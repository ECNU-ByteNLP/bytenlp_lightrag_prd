### PRD文档分析专用配置文件示例
### 复制此文件为 .env 并根据需要修改配置

###########################
### 服务器配置
###########################
HOST=0.0.0.0
PORT=9621
WEBUI_TITLE='PRD功能分析系统'
WEBUI_DESCRIPTION="专业的PRD文档功能点抽取和关系分析系统"

### 工作目录配置
INPUT_DIR=./inputs
WORKING_DIR=./rag_storage

### 日志级别
LOG_LEVEL=INFO
VERBOSE=True

#####################################
### 查询配置
#####################################
ENABLE_LLM_CACHE=true
COSINE_THRESHOLD=0.2
TOP_K=60
CHUNK_TOP_K=10
MAX_ENTITY_TOKENS=15000
MAX_RELATION_TOKENS=15000
MAX_TOTAL_TOKENS=40000
RELATED_CHUNK_NUMBER=5

### 重排序配置
ENABLE_RERANK=True
MIN_RERANK_SCORE=0.3
RERANK_MODEL=jina-reranker-v2-base-multilingual
RERANK_BINDING_HOST=https://api.jina.ai/v1/rerank
RERANK_BINDING_API_KEY=your_rerank_api_key_here

########################################
### 文档处理配置
########################################
### 语言设置
SUMMARY_LANGUAGE=Chinese
ENABLE_LLM_CACHE_FOR_EXTRACT=true

### 文档分块配置
CHUNK_SIZE=1500
CHUNK_OVERLAP_SIZE=200

### 实体抽取配置
FORCE_LLM_SUMMARY_ON_MERGE=4
MAX_TOKENS=15000
MAX_GLEANING=2

###############################
### 并发配置
###############################
MAX_ASYNC=6
MAX_PARALLEL_INSERT=3
EMBEDDING_FUNC_MAX_ASYNC=12
EMBEDDING_BATCH_NUM=16

###########################################################
### LLM配置
###########################################################
LLM_BINDING=openai
LLM_MODEL=gpt-4o
LLM_BINDING_HOST=https://api.openai.com/v1
LLM_BINDING_API_KEY=your_openai_api_key_here

### LLM参数
TEMPERATURE=0.7
OPENAI_LLM_FREQUENCY_PENALTY=1.1

### 超时设置
TIMEOUT=300

####################################################################
### 嵌入模型配置
####################################################################
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIM=3072
EMBEDDING_BINDING_HOST=https://api.openai.com
EMBEDDING_BINDING_API_KEY=your_openai_api_key_here

### 或者使用本地Ollama
# EMBEDDING_BINDING=ollama
# EMBEDDING_MODEL=bge-m3:latest
# EMBEDDING_DIM=1024
# EMBEDDING_BINDING_HOST=http://localhost:11434

############################
### 存储选择
############################
### 推荐使用PostgreSQL进行生产部署
LIGHTRAG_KV_STORAGE=PGKVStorage
LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage
LIGHTRAG_GRAPH_STORAGE=PGGraphStorage
LIGHTRAG_VECTOR_STORAGE=PGVectorStorage

### PostgreSQL配置
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=your_username
POSTGRES_PASSWORD='your_password'
POSTGRES_DATABASE=lightrag_prd
POSTGRES_MAX_CONNECTIONS=20

### PostgreSQL向量存储配置
POSTGRES_VECTOR_INDEX_TYPE=HNSW
POSTGRES_HNSW_M=16
POSTGRES_HNSW_EF=200

### 或者使用Neo4j图形数据库（性能更好）
# LIGHTRAG_GRAPH_STORAGE=Neo4JStorage
# NEO4J_URI=neo4j://localhost:7687
# NEO4J_USERNAME=neo4j
# NEO4J_PASSWORD='your_password'
# NEO4J_DATABASE=lightrag_prd

### 或者使用Redis缓存
# LIGHTRAG_KV_STORAGE=RedisKVStorage
# LIGHTRAG_DOC_STATUS_STORAGE=RedisDocStatusStorage
# REDIS_URI=redis://localhost:6379

### 或者使用MongoDB
# LIGHTRAG_KV_STORAGE=MongoKVStorage
# LIGHTRAG_DOC_STATUS_STORAGE=MongoDocStatusStorage
# LIGHTRAG_GRAPH_STORAGE=MongoGraphStorage
# MONGO_URI=mongodb://localhost:27017/
# MONGO_DATABASE=lightrag_prd

####################################################################
### PRD专用配置
####################################################################
### 工作空间名称（用于数据隔离）
WORKSPACE=prd_analysis

### 实体类型配置（PRD专用）
# 可以在代码中通过addon_params设置：
# addon_params={"entity_types": ["主功能", "父功能点", "子功能点", "业务规则", "前置条件", "后置条件", "异常处理", "数据字段", "用户角色", "系统接口"]}

### 关系类型配置（PRD专用）
# 可以在代码中通过addon_params设置：
# addon_params={"relationship_types": ["包含关系", "依赖关系", "触发关系", "数据流向", "权限控制", "业务流程", "条件判断", "异常分支"]}

### 示例数量限制（减少LLM调用成本）
# 可以在代码中通过addon_params设置：
# addon_params={"example_number": 1}

### 语言设置
# 可以在代码中通过addon_params设置：
# addon_params={"language": "中文"}

####################################################################
### 高级配置
####################################################################
### 向量检索阈值调整
# 对于PRD文档，可能需要调整相似度阈值以获得更精确的结果
# COSINE_THRESHOLD=0.15

### 文档分块策略
# 对于PRD文档，可能需要更大的分块以保持功能点的完整性
# CHUNK_SIZE=2000
# CHUNK_OVERLAP_SIZE=300

### 实体抽取优化
# 增加抽取循环次数以获得更完整的结果
# MAX_GLEANING=3

### 缓存配置
# 启用所有缓存以减少LLM调用
ENABLE_LLM_CACHE=true
ENABLE_LLM_CACHE_FOR_EXTRACT=true

### 重排序优化
# 对于PRD文档，使用更严格的重排序阈值
# MIN_RERANK_SCORE=0.4
